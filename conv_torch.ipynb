{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.FashionMNIST('data', download=True, train=True)\n",
    "train_X = train_data.data.float()\n",
    "train_y = train_data.targets\n",
    "test_data = datasets.FashionMNIST('data', download=True, train=False)\n",
    "test_X = test_data.data.float()\n",
    "test_y = test_data.targets\n",
    "labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "print(train_X.size(),train_y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1, 32, 32])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X=train_X.unsqueeze(1)\n",
    "test_X=test_X.unsqueeze(1)\n",
    "train_X = torch.tensor(np.pad(train_X, ((0,0),(0,0),(2,2),(2,2)), 'constant')) \n",
    "test_X = torch.tensor(np.pad(test_X, ((0,0),(0,0),(2,2),(2,2)), 'constant'))\n",
    "\n",
    "\n",
    "train_X.size()\n",
    "all_idx = np.arange(len(train_X))\n",
    "np.random.shuffle(all_idx)\n",
    "train_idx = all_idx[:50000]\n",
    "dev_idx = all_idx[50000:]\n",
    "dev_X = train_X[dev_idx]\n",
    "dev_y = train_y[dev_idx]\n",
    "train_X = train_X[train_idx]\n",
    "train_y = train_y[train_idx]\n",
    "train_X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchedIterator:\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def iterate_once(self):\n",
    "        for start in range(0, len(self.X), self.batch_size):\n",
    "            end = start + self.batch_size\n",
    "            yield self.X[start:end], self.y[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.relu(torch.tensor([-5]))\n",
    "train_X.size()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1= nn.Conv2d(1,out_channels=6,kernel_size=5) #input:(N,C_in,H_in,W_in)\n",
    "        self.conv2= nn.Conv2d(6,16,kernel_size=5)\n",
    "        self.conv3= nn.Conv2d(16,120,kernel_size=5)\n",
    "        \n",
    "        self.max_pool=nn.MaxPool2d(2,2) #kernel,stride\n",
    "        \n",
    "        self.dense_1=nn.Linear(120,84)\n",
    "        self.dense_2=nn.Linear(84,10)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        h=F.relu(self.conv1(X))\n",
    "        h=self.max_pool(h)\n",
    "        h=F.relu(self.conv2(h))\n",
    "        h=self.max_pool(h)\n",
    "        h=F.relu(self.conv3(h))\n",
    "        h=h.view(-1,self.num_flat_features(h))\n",
    "        h=F.relu(self.dense_1(h))\n",
    "        out=F.relu(self.dense_2(h))\n",
    "        return out\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5])\n",
      "conv1.bias torch.Size([6])\n",
      "conv2.weight torch.Size([16, 6, 5, 5])\n",
      "conv2.bias torch.Size([16])\n",
      "conv3.weight torch.Size([120, 16, 5, 5])\n",
      "conv3.bias torch.Size([120])\n",
      "dense_1.weight torch.Size([84, 120])\n",
      "dense_1.bias torch.Size([84])\n",
      "dense_2.weight torch.Size([10, 84])\n",
      "dense_2.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "model_conv=Convolutional()\n",
    "\n",
    "for n, p in model_conv.named_parameters():\n",
    "    print(n, p.size())\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_conv.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "  train accuracy: 0.6695399880409241  train loss: 0.9920851588249207\n",
      "  dev accuracy: 0.6715999841690063  dev loss: 0.9942250847816467\n",
      "Epoch: 1\n",
      "  train accuracy: 0.7002000212669373  train loss: 0.8279196619987488\n",
      "  dev accuracy: 0.6972000002861023  dev loss: 0.841567873954773\n",
      "Epoch: 2\n",
      "  train accuracy: 0.7117199897766113  train loss: 0.7849411964416504\n",
      "  dev accuracy: 0.7088000178337097  dev loss: 0.7995408177375793\n",
      "Epoch: 3\n",
      "  train accuracy: 0.7215399742126465  train loss: 0.7590897083282471\n",
      "  dev accuracy: 0.7195000052452087  dev loss: 0.775739312171936\n",
      "Epoch: 4\n",
      "  train accuracy: 0.7283400297164917  train loss: 0.7377325296401978\n",
      "  dev accuracy: 0.7253000140190125  dev loss: 0.7566822171211243\n",
      "Epoch: 5\n",
      "  train accuracy: 0.7289999723434448  train loss: 0.7300497889518738\n",
      "  dev accuracy: 0.7232000231742859  dev loss: 0.7545873522758484\n",
      "Epoch: 6\n",
      "  train accuracy: 0.732420027256012  train loss: 0.7094653248786926\n",
      "  dev accuracy: 0.7249000072479248  dev loss: 0.7400246858596802\n",
      "Epoch: 7\n",
      "  train accuracy: 0.7342600226402283  train loss: 0.7008981108665466\n",
      "  dev accuracy: 0.7260000109672546  dev loss: 0.7411762475967407\n",
      "Epoch: 8\n",
      "  train accuracy: 0.7381200194358826  train loss: 0.6890950202941895\n",
      "  dev accuracy: 0.7272999882698059  dev loss: 0.7338910102844238\n",
      "Epoch: 9\n",
      "  train accuracy: 0.7341200113296509  train loss: 0.6999037265777588\n",
      "  dev accuracy: 0.7232999801635742  dev loss: 0.7495322227478027\n"
     ]
    }
   ],
   "source": [
    "#conv model\n",
    "batch_size = 1000\n",
    "train_iter = BatchedIterator(train_X, train_y, batch_size)\n",
    "dev_iter = BatchedIterator(dev_X, dev_y, batch_size)\n",
    "test_iter = BatchedIterator(test_X, test_y, batch_size)\n",
    "\n",
    "all_train_loss = []\n",
    "all_dev_loss = []\n",
    "all_train_acc = []\n",
    "all_dev_acc = []\n",
    "\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    # training loop\n",
    "    for bi, (batch_x, batch_y) in enumerate(train_iter.iterate_once()):\n",
    "        \n",
    "        y_out = model_conv(batch_x) #forward prop\n",
    "        loss = criterion(y_out, batch_y) #computes loss of batch\n",
    "        optimizer.zero_grad() #sets gradients of all model parameters to zero\n",
    "        loss.backward() #computes gradient \n",
    "        optimizer.step() #performs optimalisation step with adam\n",
    "        \n",
    "    # one train epoch finished, evaluate on the train and the dev set (NOT the test)\n",
    "    train_out = model_conv(train_X)\n",
    "    train_loss = criterion(train_out, train_y)\n",
    "    all_train_loss.append(train_loss.item()) #.item() tensor -> int\n",
    "    train_pred = train_out.max(axis=1)[1]\n",
    "    train_acc = torch.eq(train_pred, train_y).sum().float() / len(train_X) #.eq(x,y) counts x[i]=y[i]\n",
    "    all_train_acc.append(train_acc)\n",
    "    \n",
    "    dev_out = model_conv(dev_X)\n",
    "    dev_loss = criterion(dev_out, dev_y)\n",
    "    all_dev_loss.append(dev_loss.item())\n",
    "    dev_pred = dev_out.max(axis=1)[1]\n",
    "    dev_acc = torch.eq(dev_pred, dev_y).sum().float() / len(dev_X)\n",
    "    all_dev_acc.append(dev_acc)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}\\n  train accuracy: {train_acc}  train loss: {train_loss}\")\n",
    "    print(f\"  dev accuracy: {dev_acc}  dev loss: {dev_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200000, 720000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
