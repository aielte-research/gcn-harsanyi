{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efficient-economy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU device: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.transforms import TargetIndegree\n",
    "\n",
    "import time\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import numpy.linalg as LA\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "\n",
    "if torch.cuda.is_available() is False:\n",
    "    raise Exception(\"GPU device not found, runtime environment should be set to GPU\")\n",
    "print(f\"Using GPU device: {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "adolescent-nickel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 1113\n",
      "Number of classes: 2\n",
      "Number of node features: 3\n"
     ]
    }
   ],
   "source": [
    "dataset=TUDataset('data', 'PROTEINS', transform=TargetIndegree()) #saves normalized degree as edge_attr\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "print(f'Number of node features: {dataset.num_node_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "solar-memorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 963\n",
      "Number of test graphs: 150\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[150:]\n",
    "test_dataset = dataset[:150]\n",
    "train_loader=DataLoader(train_dataset,batch_size=100)\n",
    "test_loader=DataLoader(test_dataset,batch_size=150)\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fluid-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import ChebConv\n",
    "from torch_geometric.nn import BatchNorm\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "class Cheb(nn.Module):\n",
    "    def __init__(self, in_channel,hidden,K):\n",
    "        super().__init__()\n",
    "        self.conv1 = ChebConv(in_channel,hidden,K)\n",
    "        self.bn1 = BatchNorm(hidden)\n",
    "        self.dense1 = nn.Linear(hidden,2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden=hidden\n",
    "        self.history= None\n",
    "        \n",
    "    def forward(self,data):\n",
    "        edge_index=data.edge_index\n",
    "        h=data.x\n",
    "        h = self.conv1(h, edge_index)\n",
    "        h = self.bn1(h)\n",
    "        h = self.relu(h)\n",
    "        h = global_mean_pool(h, data.batch)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.dense1(h)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "private-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import ARMAConv\n",
    "class ARMA(torch.nn.Module):\n",
    "    def __init__(self,in_channel,hidden,K,N):\n",
    "        super().__init__()\n",
    "        self.conv1 = ARMAConv(in_channel,hidden,num_stacks=K, num_layers=N)\n",
    "        self.bn1 = BatchNorm(hidden)\n",
    "        self.dense1 = nn.Linear(hidden,2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden=hidden\n",
    "        self.history= None\n",
    "        \n",
    "    def forward(self,data):\n",
    "        edge_index=data.edge_index\n",
    "        h=data.x\n",
    "        h = self.conv1(h, edge_index)\n",
    "        h = self.bn1(h)\n",
    "        h = self.relu(h)\n",
    "        h = global_mean_pool(h, data.batch)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.dense1(h)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "blessed-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SplineConv\n",
    "class Spline(torch.nn.Module):\n",
    "    def __init__(self,in_channel,hidden,kernel):\n",
    "        super().__init__()\n",
    "        self.conv1 = SplineConv(in_channel, hidden, dim=1, kernel_size=kernel)\n",
    "        self.bn1 = BatchNorm(hidden)\n",
    "        self.dense1 = torch.nn.Linear(hidden,2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        h = F.relu(self.bn1(self.conv1(data.x, data.edge_index,data.edge_attr)))\n",
    "        h = global_mean_pool(h, data.batch)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.dense1(h)\n",
    "        return h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "dimensional-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(EPOCHS, MODEL, OPTIMIZER, device, train_loader, test_loader):\n",
    "    summary(MODEL)\n",
    "    \n",
    "    if torch.cuda.is_available() is False:\n",
    "        raise Exception(\"GPU device not found, runtime environment should be set to GPU\")\n",
    "    print(f\"Using GPU device: {torch.cuda.get_device_name(device)}\")\n",
    "    \n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "    history = {'train_loss': [], 'train_accuracy': [], 'test_loss': [],'test_accuracy': []\n",
    "               ,'time':None}\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start=time.time()\n",
    "        \n",
    "        temp_loss = 0\n",
    "        correct=0\n",
    "        graphs=0\n",
    "        for step,data in enumerate(train_loader):\n",
    "            data.to(device)\n",
    "            OPTIMIZER.zero_grad()  # Clear gradients.\n",
    "            y_out = MODEL(data) # Perform a single forward pass.\n",
    "            loss = criterion(y_out, data.y)  # Compute the loss solely based on the training nodes.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            OPTIMIZER.step()  # Update parameters based on gradients.\n",
    "            \n",
    "            temp_loss=temp_loss+loss.detach().item()\n",
    "            pred = y_out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            correct =correct + int((pred == data.y).sum())\n",
    "            graphs = graphs + data.num_graphs\n",
    "            \n",
    "        train_acc=float(\"{:.2f}\".format(correct / graphs))\n",
    "        train_loss=float(\"{:.2f}\".format(temp_loss/(step+1)))\n",
    "        \n",
    "         \n",
    "        temp_loss = 0\n",
    "        correct=0\n",
    "        graphs=0  \n",
    "        for step,data in enumerate(test_loader):\n",
    "            data.to(device)\n",
    "            y_out =MODEL(data)\n",
    "            loss = criterion(y_out,  data.y) \n",
    "            \n",
    "            temp_loss =  temp_loss + loss.detach().item()\n",
    "            pred = y_out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            correct =correct + int((pred == data.y).sum())\n",
    "            graphs = graphs + data.num_graphs\n",
    "        \n",
    "        test_acc=float(\"{:.2f}\".format(correct / graphs))\n",
    "        test_loss=float(\"{:.2f}\".format(temp_loss/(step+1)))\n",
    "        \n",
    "        end=time.time()\n",
    "        \n",
    "        print(f\"Epoch: {epoch} | Train loss: {train_loss} | Train accuracy: {train_acc}  | Test loss: {test_loss} | Test accuracy: {test_acc}| Time: {end-start}\")\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_accuracy'].append(train_acc)\n",
    "        history['test_accuracy'].append(test_acc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['time']=end-start\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "aggressive-industry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─ChebConv: 1-1                          2,730\n",
      "├─BatchNorm: 1-2                         --\n",
      "|    └─BatchNorm1d: 2-1                  60\n",
      "├─Linear: 1-3                            62\n",
      "├─ReLU: 1-4                              --\n",
      "=================================================================\n",
      "Total params: 2,852\n",
      "Trainable params: 2,852\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "Using GPU device: GeForce RTX 2080 Ti\n",
      "Epoch: 0 | Train loss: 0.68 | Train accuracy: 0.63  | Test loss: 0.65 | Test accuracy: 0.65| Time: 0.2850046157836914\n",
      "Epoch: 1 | Train loss: 0.64 | Train accuracy: 0.64  | Test loss: 0.63 | Test accuracy: 0.65| Time: 0.2621893882751465\n",
      "Epoch: 2 | Train loss: 0.61 | Train accuracy: 0.69  | Test loss: 0.61 | Test accuracy: 0.71| Time: 0.27790069580078125\n",
      "Epoch: 3 | Train loss: 0.59 | Train accuracy: 0.71  | Test loss: 0.6 | Test accuracy: 0.73| Time: 0.28606081008911133\n",
      "Epoch: 4 | Train loss: 0.58 | Train accuracy: 0.71  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.26187562942504883\n",
      "Epoch: 5 | Train loss: 0.57 | Train accuracy: 0.71  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.3058161735534668\n",
      "Epoch: 6 | Train loss: 0.57 | Train accuracy: 0.71  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.29365038871765137\n",
      "Epoch: 7 | Train loss: 0.57 | Train accuracy: 0.72  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.26073765754699707\n",
      "Epoch: 8 | Train loss: 0.57 | Train accuracy: 0.72  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.2624952793121338\n",
      "Epoch: 9 | Train loss: 0.57 | Train accuracy: 0.71  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.25721240043640137\n",
      "Epoch: 10 | Train loss: 0.56 | Train accuracy: 0.72  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.25400400161743164\n",
      "Epoch: 11 | Train loss: 0.56 | Train accuracy: 0.71  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.2564876079559326\n",
      "Epoch: 12 | Train loss: 0.56 | Train accuracy: 0.71  | Test loss: 0.59 | Test accuracy: 0.7| Time: 0.25467538833618164\n",
      "Epoch: 13 | Train loss: 0.56 | Train accuracy: 0.72  | Test loss: 0.59 | Test accuracy: 0.7| Time: 0.26918792724609375\n",
      "Epoch: 14 | Train loss: 0.56 | Train accuracy: 0.71  | Test loss: 0.59 | Test accuracy: 0.7| Time: 0.33922362327575684\n",
      "Epoch: 15 | Train loss: 0.56 | Train accuracy: 0.71  | Test loss: 0.59 | Test accuracy: 0.71| Time: 0.5667753219604492\n",
      "Epoch: 16 | Train loss: 0.56 | Train accuracy: 0.71  | Test loss: 0.59 | Test accuracy: 0.71| Time: 0.3076615333557129\n",
      "Epoch: 17 | Train loss: 0.55 | Train accuracy: 0.72  | Test loss: 0.59 | Test accuracy: 0.73| Time: 0.22269034385681152\n",
      "Epoch: 18 | Train loss: 0.55 | Train accuracy: 0.72  | Test loss: 0.59 | Test accuracy: 0.72| Time: 0.20875811576843262\n",
      "Epoch: 19 | Train loss: 0.55 | Train accuracy: 0.72  | Test loss: 0.58 | Test accuracy: 0.73| Time: 0.21249866485595703\n",
      "Epoch: 20 | Train loss: 0.55 | Train accuracy: 0.72  | Test loss: 0.58 | Test accuracy: 0.73| Time: 0.21484088897705078\n",
      "Epoch: 21 | Train loss: 0.55 | Train accuracy: 0.72  | Test loss: 0.58 | Test accuracy: 0.73| Time: 0.2192399501800537\n",
      "Epoch: 22 | Train loss: 0.55 | Train accuracy: 0.73  | Test loss: 0.58 | Test accuracy: 0.73| Time: 0.18674349784851074\n",
      "Epoch: 23 | Train loss: 0.54 | Train accuracy: 0.73  | Test loss: 0.58 | Test accuracy: 0.73| Time: 0.17096233367919922\n",
      "Epoch: 24 | Train loss: 0.54 | Train accuracy: 0.73  | Test loss: 0.58 | Test accuracy: 0.73| Time: 0.17200493812561035\n",
      "Epoch: 25 | Train loss: 0.54 | Train accuracy: 0.73  | Test loss: 0.58 | Test accuracy: 0.73| Time: 0.1706702709197998\n",
      "Epoch: 26 | Train loss: 0.54 | Train accuracy: 0.73  | Test loss: 0.58 | Test accuracy: 0.73| Time: 0.1706833839416504\n",
      "Epoch: 27 | Train loss: 0.54 | Train accuracy: 0.73  | Test loss: 0.58 | Test accuracy: 0.74| Time: 0.17194390296936035\n",
      "Epoch: 28 | Train loss: 0.54 | Train accuracy: 0.73  | Test loss: 0.58 | Test accuracy: 0.73| Time: 0.17111635208129883\n",
      "Epoch: 29 | Train loss: 0.53 | Train accuracy: 0.74  | Test loss: 0.58 | Test accuracy: 0.74| Time: 0.17112398147583008\n",
      "Epoch: 30 | Train loss: 0.53 | Train accuracy: 0.73  | Test loss: 0.57 | Test accuracy: 0.74| Time: 0.1710658073425293\n",
      "Epoch: 31 | Train loss: 0.53 | Train accuracy: 0.74  | Test loss: 0.58 | Test accuracy: 0.74| Time: 0.18161296844482422\n",
      "Epoch: 32 | Train loss: 0.53 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.74| Time: 0.17179656028747559\n",
      "Epoch: 33 | Train loss: 0.53 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.17260193824768066\n",
      "Epoch: 34 | Train loss: 0.53 | Train accuracy: 0.73  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.1765580177307129\n",
      "Epoch: 35 | Train loss: 0.53 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.17443013191223145\n",
      "Epoch: 36 | Train loss: 0.53 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.17200922966003418\n",
      "Epoch: 37 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.17438983917236328\n",
      "Epoch: 38 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.17449736595153809\n",
      "Epoch: 39 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.1772294044494629\n",
      "Epoch: 40 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.74| Time: 0.17574334144592285\n",
      "Epoch: 41 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.17496609687805176\n",
      "Epoch: 42 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.17835760116577148\n",
      "Epoch: 43 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.74| Time: 0.17206287384033203\n",
      "Epoch: 44 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.17449617385864258\n",
      "Epoch: 45 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.74| Time: 0.17077088356018066\n",
      "Epoch: 46 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.74| Time: 0.17203879356384277\n",
      "Epoch: 47 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.17082667350769043\n",
      "Epoch: 48 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.74| Time: 0.17081928253173828\n",
      "Epoch: 49 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.57 | Test accuracy: 0.75| Time: 0.21772313117980957\n"
     ]
    }
   ],
   "source": [
    "##TODOtrain\n",
    "device = torch.cuda.current_device()\n",
    "MODEL_Cheb=Cheb(3,30,30).to(device)\n",
    "OPTIMIZER =  torch.optim.Adam(MODEL_Cheb.parameters(), lr=0.003)   \n",
    "EPOCHS = 50\n",
    "\n",
    "Cheb_history = training_loop(EPOCHS, MODEL_Cheb, OPTIMIZER, device,train_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "announced-medication",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─ARMAConv: 1-1                          3,330\n",
      "├─BatchNorm: 1-2                         --\n",
      "|    └─BatchNorm1d: 2-1                  60\n",
      "├─Linear: 1-3                            62\n",
      "├─ReLU: 1-4                              --\n",
      "=================================================================\n",
      "Total params: 3,452\n",
      "Trainable params: 3,452\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "Using GPU device: GeForce RTX 2080 Ti\n",
      "Epoch: 0 | Train loss: 0.68 | Train accuracy: 0.59  | Test loss: 0.67 | Test accuracy: 0.61| Time: 0.12637710571289062\n",
      "Epoch: 1 | Train loss: 0.67 | Train accuracy: 0.59  | Test loss: 0.67 | Test accuracy: 0.61| Time: 0.1127007007598877\n",
      "Epoch: 2 | Train loss: 0.67 | Train accuracy: 0.59  | Test loss: 0.66 | Test accuracy: 0.61| Time: 0.10304117202758789\n",
      "Epoch: 3 | Train loss: 0.67 | Train accuracy: 0.59  | Test loss: 0.66 | Test accuracy: 0.61| Time: 0.10242152214050293\n",
      "Epoch: 4 | Train loss: 0.67 | Train accuracy: 0.6  | Test loss: 0.66 | Test accuracy: 0.63| Time: 0.09877300262451172\n",
      "Epoch: 5 | Train loss: 0.66 | Train accuracy: 0.62  | Test loss: 0.66 | Test accuracy: 0.62| Time: 0.10276556015014648\n",
      "Epoch: 6 | Train loss: 0.66 | Train accuracy: 0.62  | Test loss: 0.66 | Test accuracy: 0.63| Time: 0.10155773162841797\n",
      "Epoch: 7 | Train loss: 0.66 | Train accuracy: 0.63  | Test loss: 0.66 | Test accuracy: 0.64| Time: 0.10654807090759277\n",
      "Epoch: 8 | Train loss: 0.66 | Train accuracy: 0.63  | Test loss: 0.66 | Test accuracy: 0.65| Time: 0.10406613349914551\n",
      "Epoch: 9 | Train loss: 0.66 | Train accuracy: 0.63  | Test loss: 0.65 | Test accuracy: 0.65| Time: 0.09669733047485352\n",
      "Epoch: 10 | Train loss: 0.66 | Train accuracy: 0.63  | Test loss: 0.65 | Test accuracy: 0.65| Time: 0.09799695014953613\n",
      "Epoch: 11 | Train loss: 0.65 | Train accuracy: 0.63  | Test loss: 0.65 | Test accuracy: 0.65| Time: 0.09796476364135742\n",
      "Epoch: 12 | Train loss: 0.65 | Train accuracy: 0.62  | Test loss: 0.65 | Test accuracy: 0.66| Time: 0.09835577011108398\n",
      "Epoch: 13 | Train loss: 0.65 | Train accuracy: 0.63  | Test loss: 0.65 | Test accuracy: 0.66| Time: 0.09768915176391602\n",
      "Epoch: 14 | Train loss: 0.65 | Train accuracy: 0.63  | Test loss: 0.65 | Test accuracy: 0.66| Time: 0.09861564636230469\n",
      "Epoch: 15 | Train loss: 0.64 | Train accuracy: 0.63  | Test loss: 0.64 | Test accuracy: 0.66| Time: 0.09770345687866211\n",
      "Epoch: 16 | Train loss: 0.64 | Train accuracy: 0.63  | Test loss: 0.64 | Test accuracy: 0.65| Time: 0.10307574272155762\n",
      "Epoch: 17 | Train loss: 0.64 | Train accuracy: 0.64  | Test loss: 0.64 | Test accuracy: 0.66| Time: 0.09903287887573242\n",
      "Epoch: 18 | Train loss: 0.64 | Train accuracy: 0.64  | Test loss: 0.64 | Test accuracy: 0.67| Time: 0.0997769832611084\n",
      "Epoch: 19 | Train loss: 0.64 | Train accuracy: 0.64  | Test loss: 0.64 | Test accuracy: 0.68| Time: 0.10061979293823242\n",
      "Epoch: 20 | Train loss: 0.64 | Train accuracy: 0.64  | Test loss: 0.64 | Test accuracy: 0.68| Time: 0.09823799133300781\n",
      "Epoch: 21 | Train loss: 0.63 | Train accuracy: 0.67  | Test loss: 0.64 | Test accuracy: 0.71| Time: 0.09626555442810059\n",
      "Epoch: 22 | Train loss: 0.63 | Train accuracy: 0.69  | Test loss: 0.64 | Test accuracy: 0.71| Time: 0.09671568870544434\n",
      "Epoch: 23 | Train loss: 0.63 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.71| Time: 0.0968623161315918\n",
      "Epoch: 24 | Train loss: 0.63 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.71| Time: 0.0988626480102539\n",
      "Epoch: 25 | Train loss: 0.63 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.71| Time: 0.10728931427001953\n",
      "Epoch: 26 | Train loss: 0.63 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.71| Time: 0.10738420486450195\n",
      "Epoch: 27 | Train loss: 0.63 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.71| Time: 0.10548019409179688\n",
      "Epoch: 28 | Train loss: 0.62 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.71| Time: 0.2281785011291504\n",
      "Epoch: 29 | Train loss: 0.62 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.72| Time: 0.30294013023376465\n",
      "Epoch: 30 | Train loss: 0.62 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.72| Time: 0.29791259765625\n",
      "Epoch: 31 | Train loss: 0.62 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.73| Time: 0.251600980758667\n",
      "Epoch: 32 | Train loss: 0.62 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.73| Time: 0.12171220779418945\n",
      "Epoch: 33 | Train loss: 0.62 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.73| Time: 0.10640883445739746\n",
      "Epoch: 34 | Train loss: 0.62 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.72| Time: 0.09659361839294434\n",
      "Epoch: 35 | Train loss: 0.62 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.72| Time: 0.09952020645141602\n",
      "Epoch: 36 | Train loss: 0.62 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.72| Time: 0.1013784408569336\n",
      "Epoch: 37 | Train loss: 0.62 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.72| Time: 0.10057497024536133\n",
      "Epoch: 38 | Train loss: 0.62 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.71| Time: 0.10355854034423828\n",
      "Epoch: 39 | Train loss: 0.62 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.71| Time: 0.11096644401550293\n",
      "Epoch: 40 | Train loss: 0.61 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.7| Time: 0.11083436012268066\n",
      "Epoch: 41 | Train loss: 0.61 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.7| Time: 0.09633278846740723\n",
      "Epoch: 42 | Train loss: 0.61 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.7| Time: 0.08771896362304688\n",
      "Epoch: 43 | Train loss: 0.61 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.7| Time: 0.08856773376464844\n",
      "Epoch: 44 | Train loss: 0.61 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.7| Time: 0.08842921257019043\n",
      "Epoch: 45 | Train loss: 0.61 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.7| Time: 0.08777761459350586\n",
      "Epoch: 46 | Train loss: 0.61 | Train accuracy: 0.69  | Test loss: 0.63 | Test accuracy: 0.7| Time: 0.1291639804840088\n",
      "Epoch: 47 | Train loss: 0.61 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.71| Time: 0.128462553024292\n",
      "Epoch: 48 | Train loss: 0.61 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.71| Time: 0.11448979377746582\n",
      "Epoch: 49 | Train loss: 0.61 | Train accuracy: 0.7  | Test loss: 0.63 | Test accuracy: 0.71| Time: 0.08793449401855469\n"
     ]
    }
   ],
   "source": [
    "device = torch.cuda.current_device()\n",
    "MODEL_ARMA=ARMA(3,K=3,N=1, hidden=30).to(device)\n",
    "OPTIMIZER =  torch.optim.Adam(MODEL_ARMA.parameters(), lr=0.003)   \n",
    "EPOCHS = 50\n",
    "\n",
    "ARMA_history = training_loop(EPOCHS, MODEL_ARMA, OPTIMIZER, device,train_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "exotic-andorra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "veterinary-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─SplineConv: 1-1                        1,020\n",
      "├─BatchNorm: 1-2                         --\n",
      "|    └─BatchNorm1d: 2-1                  60\n",
      "├─Linear: 1-3                            62\n",
      "=================================================================\n",
      "Total params: 1,142\n",
      "Trainable params: 1,142\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "Using GPU device: GeForce RTX 2080 Ti\n",
      "Epoch: 0 | Train loss: 0.66 | Train accuracy: 0.62  | Test loss: 0.65 | Test accuracy: 0.61| Time: 0.1609508991241455\n",
      "Epoch: 1 | Train loss: 0.62 | Train accuracy: 0.66  | Test loss: 0.63 | Test accuracy: 0.65| Time: 0.14517998695373535\n",
      "Epoch: 2 | Train loss: 0.6 | Train accuracy: 0.67  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.14477276802062988\n",
      "Epoch: 3 | Train loss: 0.58 | Train accuracy: 0.7  | Test loss: 0.62 | Test accuracy: 0.71| Time: 0.1489267349243164\n",
      "Epoch: 4 | Train loss: 0.57 | Train accuracy: 0.7  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.14553546905517578\n",
      "Epoch: 5 | Train loss: 0.56 | Train accuracy: 0.71  | Test loss: 0.61 | Test accuracy: 0.72| Time: 0.14731884002685547\n",
      "Epoch: 6 | Train loss: 0.56 | Train accuracy: 0.71  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.1457204818725586\n",
      "Epoch: 7 | Train loss: 0.55 | Train accuracy: 0.71  | Test loss: 0.61 | Test accuracy: 0.71| Time: 0.14890408515930176\n",
      "Epoch: 8 | Train loss: 0.55 | Train accuracy: 0.72  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.1473073959350586\n",
      "Epoch: 9 | Train loss: 0.54 | Train accuracy: 0.72  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.14614009857177734\n",
      "Epoch: 10 | Train loss: 0.54 | Train accuracy: 0.73  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.14838147163391113\n",
      "Epoch: 11 | Train loss: 0.54 | Train accuracy: 0.73  | Test loss: 0.6 | Test accuracy: 0.72| Time: 0.14744853973388672\n",
      "Epoch: 12 | Train loss: 0.54 | Train accuracy: 0.73  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.15299129486083984\n",
      "Epoch: 13 | Train loss: 0.53 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.1484508514404297\n",
      "Epoch: 14 | Train loss: 0.53 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.1470499038696289\n",
      "Epoch: 15 | Train loss: 0.53 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.72| Time: 0.14780926704406738\n",
      "Epoch: 16 | Train loss: 0.53 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.1480119228363037\n",
      "Epoch: 17 | Train loss: 0.53 | Train accuracy: 0.73  | Test loss: 0.6 | Test accuracy: 0.72| Time: 0.15454697608947754\n",
      "Epoch: 18 | Train loss: 0.53 | Train accuracy: 0.74  | Test loss: 0.59 | Test accuracy: 0.71| Time: 0.15289831161499023\n",
      "Epoch: 19 | Train loss: 0.52 | Train accuracy: 0.73  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.15080499649047852\n",
      "Epoch: 20 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.14864444732666016\n",
      "Epoch: 21 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.59 | Test accuracy: 0.71| Time: 0.15070819854736328\n",
      "Epoch: 22 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.1495816707611084\n",
      "Epoch: 23 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.15252351760864258\n",
      "Epoch: 24 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.15365076065063477\n",
      "Epoch: 25 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.15084600448608398\n",
      "Epoch: 26 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.14910078048706055\n",
      "Epoch: 27 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.61 | Test accuracy: 0.71| Time: 0.14994382858276367\n",
      "Epoch: 28 | Train loss: 0.52 | Train accuracy: 0.75  | Test loss: 0.61 | Test accuracy: 0.71| Time: 0.14878416061401367\n",
      "Epoch: 29 | Train loss: 0.52 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.15002107620239258\n",
      "Epoch: 30 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.15154099464416504\n",
      "Epoch: 31 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.15305399894714355\n",
      "Epoch: 32 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.14920926094055176\n",
      "Epoch: 33 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.69| Time: 0.15071821212768555\n",
      "Epoch: 34 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.1485579013824463\n",
      "Epoch: 35 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.69| Time: 0.14986038208007812\n",
      "Epoch: 36 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.69| Time: 0.1483609676361084\n",
      "Epoch: 37 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.14943289756774902\n",
      "Epoch: 38 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.15018224716186523\n",
      "Epoch: 39 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.7| Time: 0.15555763244628906\n",
      "Epoch: 40 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.14857864379882812\n",
      "Epoch: 41 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.14683198928833008\n",
      "Epoch: 42 | Train loss: 0.51 | Train accuracy: 0.75  | Test loss: 0.61 | Test accuracy: 0.7| Time: 0.14502310752868652\n",
      "Epoch: 43 | Train loss: 0.51 | Train accuracy: 0.75  | Test loss: 0.61 | Test accuracy: 0.7| Time: 0.1470026969909668\n",
      "Epoch: 44 | Train loss: 0.51 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.14857935905456543\n",
      "Epoch: 45 | Train loss: 0.5 | Train accuracy: 0.75  | Test loss: 0.6 | Test accuracy: 0.72| Time: 0.14760231971740723\n",
      "Epoch: 46 | Train loss: 0.5 | Train accuracy: 0.75  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.14631366729736328\n",
      "Epoch: 47 | Train loss: 0.5 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.15121006965637207\n",
      "Epoch: 48 | Train loss: 0.5 | Train accuracy: 0.74  | Test loss: 0.6 | Test accuracy: 0.71| Time: 0.1462864875793457\n",
      "Epoch: 49 | Train loss: 0.5 | Train accuracy: 0.75  | Test loss: 0.61 | Test accuracy: 0.71| Time: 0.1476144790649414\n"
     ]
    }
   ],
   "source": [
    "device = torch.cuda.current_device()\n",
    "MODEL_Spline=Spline(3,hidden=30,kernel=10).to(device)\n",
    "OPTIMIZER =  torch.optim.Adam(MODEL_Spline.parameters(), lr=0.03)   \n",
    "EPOCHS = 50\n",
    "\n",
    "Spline_history = training_loop(EPOCHS, MODEL_Spline, OPTIMIZER, device,train_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-criterion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
